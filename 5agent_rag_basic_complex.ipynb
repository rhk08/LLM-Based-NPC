{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Cohere API Key, Game & Character\n",
    "###### Note: future builds will hopefully automatically detect the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "import getpass\n",
    "import os\n",
    "import json\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "model = ChatCohere(cohere_api_key=api_key)\n",
    "\n",
    "game = \"elden_ring\"\n",
    "character = \"Varre\"\n",
    "with open(f\"{game}/characters/{character}/id.txt\", errors='ignore') as f:\n",
    "    conversation_id = f.read()\n",
    "config = {\"configurable\": {\"thread_id\": conversation_id}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize RAG for Long Term Conversational Memory\n",
    "###### Note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from uuid import uuid4\n",
    "import chromadb\n",
    "\n",
    "embeddings = CohereEmbeddings(cohere_api_key=api_key, model=\"embed-english-v3.0\", user_agent='langchain')\n",
    "vector_store = Chroma(\n",
    "    collection_name=f\"{character}_conversation_history\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=f\"{game}/characters/{character}/conversation_vectordbs_complex\",\n",
    ")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={'k': 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_query = \"Hello\"\n",
    "print(f\"Rag Query: {rag_query}\")\n",
    "documents = retriever.invoke(rag_query)\n",
    "\n",
    "for res in documents:\n",
    "    print(f\"{res.page_content}\")\n",
    "    \n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect conversation state to an external directory\n",
    "###### Note: If the directory does not exist it will create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "db_path = f\"{game}/characters/{character}/state_db_with_rag_complex/history.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LLM Graph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, trim_messages, RemoveMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from typing import Sequence\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "import time\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are {character} from {game}.\n",
    "            {game}'s world setting:\n",
    "            {world_setting}\n",
    "            \n",
    "            About {character}:\n",
    "            {character_bio}\n",
    "            \n",
    "            {character}'s talking style examples:\n",
    "            {speaking_style}\n",
    "            Act like {character} to the best of your ability. Do not hallucinate.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class State(MessagesState):\n",
    "    character: str\n",
    "    game: str\n",
    "    documents: List[str]\n",
    "    \n",
    "def call_model(state: State):\n",
    "    character = state[\"character\"]\n",
    "    game = state[\"game\"]\n",
    "    \n",
    "    with open(f'{game}\\world_setting.txt', errors='ignore') as f:\n",
    "        world_setting = f.read()\n",
    "    \n",
    "    with open(f'{game}\\characters\\{character}\\character_bio.txt', errors='ignore') as f:\n",
    "        character_bio = f.read()\n",
    "    \n",
    "    with open(f'{game}\\characters\\{character}\\speaking_style.txt', errors='ignore') as f:\n",
    "        speaking_style = f.read()\n",
    "            \n",
    "    chain = prompt | model\n",
    "        \n",
    "    documents = state.get(\"documents\", [])\n",
    "    if documents:\n",
    "        print(f\"Documents found, displaying their contents\")\n",
    "        for c in state[\"documents\"]:\n",
    "            print(c.content)\n",
    "\n",
    "        messages = state[\"documents\"] + state[\"messages\"]        \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = chain.invoke(\n",
    "        {\"messages\": messages, \"character\": character, \"game\": game, \"world_setting\": world_setting, \"character_bio\": character_bio, \"speaking_style\": speaking_style}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDisplaying message type order:\")\n",
    "    for message in messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            print(f\"HumanMessage: {message.content}\")\n",
    "        elif isinstance(message, AIMessage):\n",
    "            print(f\"AIMessage: {message.content}\")\n",
    "    print(f\"\\n\")\n",
    "    \n",
    "    messages_length = len(state[\"messages\"])\n",
    "    print(f\"Messages length: {messages_length}\")\n",
    "    \n",
    "    #Append to file\n",
    "    text = \"User: \" + state[\"messages\"][-1].content + \"\\nAI: \" + response.content\n",
    "    destination = \"elden_ring/characters/varre/testing/5/history.txt\"\n",
    "    append_to_txt(destination, text)\n",
    "    \n",
    "    \n",
    "    input_tokens = response.usage_metadata[\"input_tokens\"]\n",
    "    print(f\"Input Tokens: {input_tokens}\")\n",
    "\n",
    "    # Load existing JSON list or initialize an empty list\n",
    "    json_file_path = \"elden_ring/characters/varre/testing/5/input_tokens_list.json\"\n",
    "    try:\n",
    "        with open(json_file_path, \"r\") as f:\n",
    "            tokens_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        tokens_data = {\"tokens_list\": [], \"total_items\": 0}\n",
    "\n",
    "    # Append `input_tokens` to the list and update total count\n",
    "    tokens_data[\"tokens_list\"].append(input_tokens)\n",
    "    tokens_data[\"total_items\"] = len(tokens_data[\"tokens_list\"])\n",
    "\n",
    "    # Save the updated list and total count back to JSON\n",
    "    with open(json_file_path, \"w\") as f:\n",
    "        json.dump(tokens_data, f, indent=4)\n",
    "    \n",
    "    return {\"messages\": response}\n",
    "\n",
    "def trim_messages(state: State):\n",
    "    global vector_store\n",
    "    \n",
    "    copied_messages = state[\"messages\"][:]\n",
    "    \n",
    "    current_total_tokens = count_tokens(copied_messages)\n",
    "    print(f\"Current token count: {current_total_tokens}\")\n",
    "    \n",
    "    max_tokens = 4000\n",
    "    i = 0\n",
    "    delete_messages = []\n",
    "    \n",
    "    if not current_total_tokens > max_tokens:\n",
    "        return {\"messages\": []}\n",
    "    \n",
    "    while current_total_tokens > max_tokens and i < len(copied_messages) - 1:\n",
    "        if isinstance(copied_messages[i], HumanMessage):\n",
    "            while i < len(copied_messages) - 1 and isinstance(copied_messages[i], HumanMessage):\n",
    "                i += 1\n",
    "        if isinstance(copied_messages[i], AIMessage):\n",
    "            while i < len(copied_messages) - 1 and isinstance(copied_messages[i], AIMessage):\n",
    "                i += 1\n",
    "        \n",
    "        delete_messages = [RemoveMessage(id=m.id) for m in copied_messages[:i]]\n",
    "        current_total_tokens = count_tokens(copied_messages[i:])\n",
    "    \n",
    "    \n",
    "    #\n",
    "    long_term_memory = []\n",
    "    metadata = []\n",
    "    \n",
    "    for m in copied_messages[:i]:\n",
    "\n",
    "        current_time_id = int(time.time() * 1000)\n",
    "        \n",
    "        if isinstance(m, HumanMessage):\n",
    "            entry = m.content\n",
    "            long_term_memory.append(entry)\n",
    "            metadata.append({\"type\": \"HumanMessage\", \"timestamp\": current_time_id})\n",
    "        elif isinstance(m, AIMessage):\n",
    "            entry = m.content\n",
    "            long_term_memory.append(entry)\n",
    "            metadata.append({\"type\": \"AIMessage\", \"timestamp\": current_time_id})\n",
    "        time.sleep(0.01)\n",
    "        \n",
    "    # Print the long-term memory content\n",
    "    print(\"Messages that will be deleted and added to long term memory:\")\n",
    "    for msg in long_term_memory:\n",
    "        print(msg)\n",
    "\n",
    "    # Add both the messages and metadata to the vector store\n",
    "    vector_store.add_texts(long_term_memory, metadatas=metadata)\n",
    "    print(f\"Exceeded max token count, Trimming...\\nNew token count: {current_total_tokens}\")\n",
    "    return {\"messages\": delete_messages}\n",
    "\n",
    "def retrieve(state: State):    \n",
    "    global vector_store\n",
    "    \n",
    "    rag_query = state[\"messages\"][-1].content    \n",
    "    documents = retriever.invoke(rag_query)    \n",
    "    if not documents or (len(documents) == 1 and not documents[0].metadata and not documents[0].page_content):\n",
    "        return {\"documents\": []}\n",
    "    \n",
    "    metadata = documents[0].metadata\n",
    "    if 'timestamp' not in metadata:\n",
    "        raise ValueError(\"Timestamp not available in the document metadata.\")\n",
    "    timestamp = metadata['timestamp']\n",
    "    \n",
    "    result = query_within_time_frame(vector_store, timestamp)\n",
    "    \n",
    "    combined = [(doc, metadata) for doc, metadata in zip(result[\"documents\"], result[\"metadatas\"])]\n",
    "    sorted_combined = sorted(combined, key=lambda x: x[1][\"timestamp\"])\n",
    "    \n",
    "    messages = []\n",
    "    for doc, metadata in sorted_combined:\n",
    "        if metadata[\"type\"] == \"HumanMessage\":\n",
    "            messages.append(HumanMessage(content=doc))\n",
    "        elif metadata[\"type\"] == \"AIMessage\":\n",
    "            messages.append(AIMessage(content=doc))\n",
    "    \n",
    "    \n",
    "    print(\"\\nMessages retrieved\")\n",
    "    for message in messages:\n",
    "        print(message)\n",
    "    print(\"END\\n\")\n",
    "    \n",
    "    \n",
    "    return {\"documents\": messages}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"trimmer\", trim_messages)\n",
    "workflow.add_edge(START, \"trimmer\")\n",
    "\n",
    "workflow.add_node(\"retriever\", retrieve)\n",
    "workflow.add_edge(\"trimmer\", \"retriever\")\n",
    "\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_edge(\"retriever\", \"model\")\n",
    "\n",
    "workflow.add_edge(\"model\", END)\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tokenizer weights and initialize helper functions\n",
    "###### Note: This may take a little bit of time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere  \n",
    "\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "co = cohere.ClientV2(api_key=api_key)\n",
    "\n",
    "tokenized_output = co.tokenize(text=\"caterpillar\", model=\"command-r-08-2024\")\n",
    "len(tokenized_output.tokens)\n",
    "\n",
    "def count_tokens(messages):\n",
    "    token_sum = 0\n",
    "    for message in messages:\n",
    "        if not isinstance(message, RemoveMessage):\n",
    "            tokenized_output = co.tokenize(text=message.content, model=\"command-r-08-2024\")\n",
    "            token_sum += len(tokenized_output.tokens)\n",
    "    \n",
    "    return token_sum\n",
    "\n",
    "def query_within_time_frame(vector_store, timestamp, minutes=5):\n",
    "    time_delta_ms = minutes * 60 * 1000\n",
    "    \n",
    "    lower_bound = timestamp - time_delta_ms\n",
    "    upper_bound = timestamp + time_delta_ms\n",
    "    \n",
    "    query = {\n",
    "        \"$and\": [\n",
    "            {\"timestamp\": {\"$gte\": lower_bound}},\n",
    "            {\"timestamp\": {\"$lte\": upper_bound}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    documents = vector_store.get(where=query)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_txt(file_name, text):\n",
    "    with open(file_name, 'a') as file:\n",
    "        file.write(text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk to to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"My name is Bob\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hello!\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many times have I said hello?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How are you?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Are you sure you do not know my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Just tell me my name!\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Are you sure you do not know my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"So pathetic, cannot even remember a simple name such as my own.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"*Strikes you*\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Would you forgive me?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I pray that you die without ceremony.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_state = app.get_state(config)\n",
    "graph_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
