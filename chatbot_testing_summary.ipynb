{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanz\\Desktop\\LLM-Based-NPC\\.venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "model = ChatCohere(cohere_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in English.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import SystemMessage, RemoveMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    # If a summary exists, we add this in as a system message\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    if summary:\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "        \n",
    "    #Chain prompt template to model\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke(\n",
    "        {\"messages\": messages}\n",
    "    )\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    # First, we summarize the conversation\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    if summary:\n",
    "        # If a summary already exists, we use a different system prompt\n",
    "        # to summarize it than if one didn't\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    # We now need to delete messages that we no longer want to show up\n",
    "    # I will delete all but the last two messages, but you can change this\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `conversation`.\n",
    "    # This means these are the edges taken after the `conversation` node is called.\n",
    "    \"model\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm bob\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Bob, I'm Command. How can I help you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob. Is there anything else I can help you with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "i like the celtics!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Celtics are a professional basketball team based in Boston, Massachusetts. They compete in the National Basketball Association (NBA) as part of the league's Eastern Conference Atlantic Division. The Celtics have won a record 17 NBA championships, the most of any NBA franchise.\n",
      "\n",
      "Would you like to know more about the Celtics?\n"
     ]
    }
   ],
   "source": [
    "def print_update(update):\n",
    "    for k, v in update.items():\n",
    "        for m in v[\"messages\"]:\n",
    "            m.pretty_print()\n",
    "        if \"summary\" in v:\n",
    "            print(v[\"summary\"])\n",
    "            \n",
    "            \n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"hi! I'm bob\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the celtics!\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "i like how much they win\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Celtics have indeed been a dominant force in the NBA, especially during the 1950s and 1960s, when they won 11 championships in 13 years, a feat that has not been matched since. This era was led by legendary players like Bob Cousy, Bill Russell, and Tom Heinsohn, who helped establish the Celtics' winning culture.\n",
      "\n",
      "In recent years, the Celtics have continued their tradition of success, reaching the NBA Finals in 2008, 2010, and 2022, winning the championship in 2008. The team's success can be attributed to a combination of skilled players, strategic coaching, and a strong front office.\n",
      "\n",
      "If you'd like, I can provide more details about the Celtics' recent seasons and notable players.\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Bob, a fan of the Boston Celtics, engaged with the AI assistant to discuss his favorite team. The Celtics, a highly successful NBA franchise, are known for their remarkable winning record, especially during the 1950s and 1960s, when they dominated the league. With 17 NBA championships, they hold the record for most titles. The conversation highlighted the team's rich history, including their rivalry with the Los Angeles Lakers. Bob expressed his appreciation for the Celtics' winning culture, which was exemplified by their recent appearances in the NBA Finals. The AI assistant provided insights into the team's legendary players from the past and their modern-day success, offering to delve further into the team's recent performance and notable players.\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"i like how much they win\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='my name is bob.', additional_kwargs={}, response_metadata={}, id='5bf33737-5508-4c05-b64e-a71d6527cc7e'),\n",
       "  AIMessage(content='I remember, Bob. Is there anything else I can help you with today?', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e355e40a-5141-404e-99d1-c70f4615fb4c', 'token_count': {'input_tokens': 390.0, 'output_tokens': 16.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e355e40a-5141-404e-99d1-c70f4615fb4c', 'token_count': {'input_tokens': 390.0, 'output_tokens': 16.0}}, id='run-e0895070-2eb8-4e77-b1b1-4e70d55ffb5e-0', usage_metadata={'input_tokens': 390, 'output_tokens': 16, 'total_tokens': 406}),\n",
       "  HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}, id='74b9f901-6642-4646-a816-19753d11f595'),\n",
       "  AIMessage(content='My name is Command. I am an AI assistant developed by Cohere. I am designed to assist you with various tasks and provide thorough responses to your queries. If you have any specific questions or need assistance with a particular topic, feel free to ask!', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e8687dbf-93c5-4daa-a217-2f81810fc553', 'token_count': {'input_tokens': 313.0, 'output_tokens': 51.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e8687dbf-93c5-4daa-a217-2f81810fc553', 'token_count': {'input_tokens': 313.0, 'output_tokens': 51.0}}, id='run-777fdd1b-ced8-4705-931e-d2194c2e9aa7-0', usage_metadata={'input_tokens': 313, 'output_tokens': 51, 'total_tokens': 364})],\n",
       " 'summary': \"In this conversation, you introduced yourself as Bob and expressed your interest in the Boston Celtics. I responded by providing information about the Celtics' history and accomplishments in the NBA. You then inquired about my name, and I shared that I am Command, an AI assistant developed by Cohere. Throughout the dialogue, I consistently offered further assistance.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = app.get_state(config).values\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob, as you introduced yourself earlier in our conversation. Is there anything else you'd like to know or discuss? I'm here to assist you with any further inquiries.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I apologize; I don't have access to personal information, including your name. In our previous conversation, you were referred to as Bob, but if that's not your name, please let me know how you'd like to be addressed, and I'll be happy to use that name in our discussion about the Boston Celtics or any other topic you'd like to explore.\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = app.invoke({\"messages\": [input_message]}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I remember, Bob. Is there anything else I can help you with today?\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"my name is bob.\")\n",
    "output = app.invoke({\"messages\": [input_message]}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Command. I am an AI assistant developed by Cohere. I am designed to assist you with various tasks and provide thorough responses to your queries. If you have any specific questions or need assistance with a particular topic, feel free to ask!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"Whats your name?\")\n",
    "output = app.invoke({\"messages\": [input_message]}, config)\n",
    "output[\"messages\"][-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
