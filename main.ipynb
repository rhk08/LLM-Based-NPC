{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File used for testing other components main files begin with the numbers 1-5 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from uuid import uuid4\n",
    "import chromadb\n",
    "\n",
    "embeddings = CohereEmbeddings(cohere_api_key=\"\", model=\"embed-english-v3.0\", user_agent='langchain')\n",
    "\n",
    "with open(f'er_text_documents/dialogue.txt', errors='ignore') as f:\n",
    "    public_world_info = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap  = 500,\n",
    "    length_function = len,\n",
    "    separators = ['\\n\\n\\n', '\\n\\n', '\\n', '.', ',', ' '],\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "documents = text_splitter.create_documents([public_world_info])\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"vectordbs\\public_world_info\",\n",
    ")\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.audio_recorder import AudioRecorder\n",
    "from tools.audio_transcriber import AudioTranscriber\n",
    "from tools.ai_chatbot_base import AIChatbotBase\n",
    "from tools.open_voice_tts import OpenVoiceTTS\n",
    "from playsound import playsound\n",
    "import keyboard\n",
    "\n",
    "def listen_for_key():\n",
    "    recorder = AudioRecorder()\n",
    "    transcriber = AudioTranscriber()\n",
    "    chatbot = AIChatbot(api_key_file='api.txt')  # Instantiate AIChat\n",
    "    open_voice_tts = OpenVoiceTTS()\n",
    "\n",
    "    try:\n",
    "        print(\"Press and hold the spacebar to record.\")\n",
    "        print(\"Release the spacebar to stop recording.\")\n",
    "        print(\"Press Esc to terminate the program.\")\n",
    "\n",
    "        while True:\n",
    "            if keyboard.is_pressed('space'):\n",
    "                if not recorder.recording:\n",
    "                    recorder.start_recording()\n",
    "\n",
    "            elif recorder.recording:\n",
    "                #record audio\n",
    "                recorder.stop_recording()\n",
    "                #transcribe audio\n",
    "                transcribed_text = transcriber.transcribe_audio(recorder.OUTPUT_FILENAME)\n",
    "\n",
    "                #pass message to ai\n",
    "                ai_response = chatbot.ask(transcribed_text, \"Annie\")\n",
    "                print(\"AI Response:\", ai_response)\n",
    "                \n",
    "                #convert response to voice\n",
    "                reference_speaker_file = 'OpenVoice/resources/demo_speaker1.mp3'\n",
    "                target_se, audio_name = open_voice_tts.extract_target_speaker(reference_speaker_file)\n",
    "                open_voice_tts.generate_audio(text=ai_response, target_se=target_se)\n",
    "                \n",
    "                #play sound\n",
    "                # audio_file_path = 'OpenVoice/outputs/output_en_default.wav'\n",
    "                # playsound(audio_file_path)\n",
    "                \n",
    "            if keyboard.is_pressed('esc'):\n",
    "                if recorder.recording:\n",
    "                    recorder.stop_recording()\n",
    "                print(\"Terminating program...\")\n",
    "                break\n",
    "    finally:\n",
    "        recorder.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    listen_for_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.ai_chatbot import AIChatbot\n",
    "\n",
    "chatbot = AIChatbot(api_key_file='api.txt',game='elden_ring',character='white_mask_varre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "import os\n",
    "           \n",
    "audio_file_path = 'OpenVoice/outputs/output_en_default.wav'\n",
    "\n",
    "if os.path.exists(audio_file_path):\n",
    "    playsound(audio_file_path)\n",
    "else:\n",
    "    print(\"Audio file does not exist.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
