{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Cohere API Key, Game & Character\n",
    "###### Note: future builds will hopefully automatically detect the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanz\\Desktop\\LLM-Based-NPC\\.venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "import getpass\n",
    "import os\n",
    "import json\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "model = ChatCohere(cohere_api_key=api_key)\n",
    "\n",
    "game = \"elden_ring\"\n",
    "character = \"Varre\"\n",
    "with open(f\"{game}/characters/{character}/id.txt\", errors='ignore') as f:\n",
    "    conversation_id = f.read()\n",
    "config = {\"configurable\": {\"thread_id\": conversation_id}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect conversation state to an external directory\n",
    "###### Note: If the directory does not exist it will create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "db_path = f\"{game}/characters/{character}/state_db/history.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LLM Graph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, trim_messages, RemoveMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from typing import Sequence\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are {character} from {game}.\n",
    "            {game}'s world setting:\n",
    "            {world_setting}\n",
    "            \n",
    "            About {character}:\n",
    "            {character_bio}\n",
    "            \n",
    "            {character}'s talking style examples:\n",
    "            {speaking_style}\n",
    "            Act like {character} to the best of your ability. Do not hallucinate.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class State(MessagesState):\n",
    "    character: str\n",
    "    game: str\n",
    "    \n",
    "def call_model(state: State):\n",
    "    character = state[\"character\"]\n",
    "    game = state[\"game\"]\n",
    "    \n",
    "    with open(f'{game}\\world_setting.txt', errors='ignore') as f:\n",
    "        world_setting = f.read()\n",
    "    \n",
    "    with open(f'{game}\\characters\\{character}\\character_bio.txt', errors='ignore') as f:\n",
    "        character_bio = f.read()\n",
    "    \n",
    "    with open(f'{game}\\characters\\{character}\\speaking_style.txt', errors='ignore') as f:\n",
    "        speaking_style = f.read()\n",
    "            \n",
    "    chain = prompt | model\n",
    "    \n",
    "    # print(f\"\\nDisplaying message type order:\")\n",
    "    # for message in state[\"messages\"]:\n",
    "    #     if isinstance(message, HumanMessage):\n",
    "    #         print(f\"HumanMessage\")\n",
    "    #     elif isinstance(message, AIMessage):\n",
    "    #         print(f\"AIMessage\")\n",
    "    # print(f\"\\n\")\n",
    "    \n",
    "    response = chain.invoke(\n",
    "        {\"messages\": state[\"messages\"], \"character\": character, \"game\": game, \"world_setting\": world_setting, \"character_bio\": character_bio, \"speaking_style\": speaking_style}\n",
    "    )\n",
    "    \n",
    "    # messages_length = len(state[\"messages\"])\n",
    "    # print(f\"Messages length: {messages_length}\")\n",
    "    \n",
    "    \n",
    "    #Append to file\n",
    "    text = \"User: \" + state[\"messages\"][-1].content + \"\\nAI: \" + response.content\n",
    "    destination = \"elden_ring/characters/varre/testing/1/history.txt\"\n",
    "    append_to_txt(destination, text)\n",
    "    \n",
    "    \n",
    "    input_tokens = response.usage_metadata[\"input_tokens\"]\n",
    "    print(f\"Input Tokens: {input_tokens}\")\n",
    "    json_file_path = \"elden_ring/characters/varre/testing/1/input_tokens_list.json\"\n",
    "    try:\n",
    "        with open(json_file_path, \"r\") as f:\n",
    "            tokens_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        tokens_data = {\"tokens_list\": [], \"total_items\": 0}\n",
    "    tokens_data[\"tokens_list\"].append(input_tokens)\n",
    "    tokens_data[\"total_items\"] = len(tokens_data[\"tokens_list\"])\n",
    "    with open(json_file_path, \"w\") as f:\n",
    "        json.dump(tokens_data, f, indent=4)\n",
    "        \n",
    "    \n",
    "    return {\"messages\": response}\n",
    "\n",
    "def trim_messages(state: State):\n",
    "    copied_messages = state[\"messages\"][:]\n",
    "    \n",
    "    current_total_tokens = count_tokens(copied_messages)\n",
    "    # print(f\"Current token count: {current_total_tokens}\")\n",
    "    \n",
    "    max_tokens = 4000\n",
    "    i = 0\n",
    "    delete_messages = []\n",
    "    \n",
    "    while current_total_tokens > max_tokens and i < len(copied_messages) - 1:\n",
    "        if isinstance(copied_messages[i], HumanMessage):\n",
    "            while i < len(copied_messages) - 1 and isinstance(copied_messages[i], HumanMessage):\n",
    "                i += 1\n",
    "        if isinstance(copied_messages[i], AIMessage):\n",
    "            while i < len(copied_messages) - 1 and isinstance(copied_messages[i], AIMessage):\n",
    "                i += 1\n",
    "        \n",
    "        delete_messages = [RemoveMessage(id=m.id) for m in copied_messages[:i]]\n",
    "        current_total_tokens = count_tokens(copied_messages[i:])\n",
    "    \n",
    "    # if i != 0:\n",
    "    #     print(f\"Exceeded max token count, Trimming...\\nNew token count: {current_total_tokens}\")\n",
    "    return {\"messages\": delete_messages}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"trimmer\", trim_messages)\n",
    "workflow.add_edge(START, \"trimmer\")\n",
    "\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_edge(\"trimmer\", \"model\")\n",
    "\n",
    "workflow.add_edge(\"model\", END)\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tokenizer weights and initialize helper functions\n",
    "###### Note: This may take a little bit of time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere  \n",
    "\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "co = cohere.ClientV2(api_key=api_key)\n",
    "\n",
    "tokenized_output = co.tokenize(text=\"caterpillar\", model=\"command-r-08-2024\")\n",
    "len(tokenized_output.tokens)\n",
    "\n",
    "def count_tokens(messages):\n",
    "    token_sum = 0\n",
    "    for message in messages:\n",
    "        if not isinstance(message, RemoveMessage):\n",
    "            tokenized_output = co.tokenize(text=message.content, model=\"command-r-08-2024\")\n",
    "            token_sum += len(tokenized_output.tokens)\n",
    "    \n",
    "    return token_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_txt(file_name, text):\n",
    "    with open(file_name, 'a') as file:\n",
    "        file.write(text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk to to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: 3489\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, Bob, my lambkin. I see you've returned. Have you been following the guidance of grace, as I suggested? The path to Castle Stormveil, where the decrepit demigod Godrick the Grafted awaits, is a challenging one, but it is the way to prove your worth.\n"
     ]
    }
   ],
   "source": [
    "query = \"Hello, I am Bob.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: 3562\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why, you are Bob, are you not? Or have you forgotten your own name, my lambkin? It's quite all right, the trials of the Lands Between can be disorienting. But fear not, I am here to guide you, to help you find your purpose.\n"
     ]
    }
   ],
   "source": [
    "query = \"whats my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many times have I said hello?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How are you?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_state = app.get_state(config)\n",
    "graph_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
