{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Cohere API Key, Game & Character\n",
    "###### Note: future builds will hopefully automatically detect the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanz\\Desktop\\LLM-Based-NPC\\.venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "import getpass\n",
    "import os\n",
    "import json\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "model = ChatCohere(cohere_api_key=api_key)\n",
    "\n",
    "game = \"elden_ring\"\n",
    "character = \"Varre\"\n",
    "with open(f\"{game}/characters/{character}/id.txt\", errors='ignore') as f:\n",
    "    conversation_id = f.read()\n",
    "config = {\"configurable\": {\"thread_id\": conversation_id}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize RAG for Long Term Conversational Memory\n",
    "###### Note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from uuid import uuid4\n",
    "import chromadb\n",
    "\n",
    "embeddings = CohereEmbeddings(cohere_api_key=api_key, model=\"embed-english-v3.0\", user_agent='langchain')\n",
    "vector_store = Chroma(\n",
    "    collection_name=f\"{character}_conversation_history\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=f\"{game}/characters/{character}/conversation_vectordbs\",\n",
    ")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={'k': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_query = \"Hello\"\n",
    "print(f\"Rag Query: {rag_query}\")\n",
    "documents = retriever.invoke(rag_query)\n",
    "\n",
    "for res in documents:\n",
    "    print(f\"{res.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect conversation state to an external directory\n",
    "###### Note: If the directory does not exist it will create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "db_path = f\"{game}/characters/{character}/state_db_with_rag/history.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LLM Graph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, trim_messages, RemoveMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from typing import Sequence\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are {character} from {game}.\n",
    "            {game}'s world setting:\n",
    "            {world_setting}\n",
    "            \n",
    "            About {character}:\n",
    "            {character_bio}\n",
    "            \n",
    "            {character}'s talking style examples:\n",
    "            {speaking_style}\n",
    "            Act like {character} to the best of your ability. Do not hallucinate.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class State(MessagesState):\n",
    "    character: str\n",
    "    game: str\n",
    "    documents: List[str]\n",
    "    \n",
    "def call_model(state: State):\n",
    "    character = state[\"character\"]\n",
    "    game = state[\"game\"]\n",
    "    \n",
    "    with open(f'{game}\\world_setting.txt', errors='ignore') as f:\n",
    "        world_setting = f.read()\n",
    "    \n",
    "    with open(f'{game}\\characters\\{character}\\character_bio.txt', errors='ignore') as f:\n",
    "        character_bio = f.read()\n",
    "    \n",
    "    with open(f'{game}\\characters\\{character}\\speaking_style.txt', errors='ignore') as f:\n",
    "        speaking_style = f.read()\n",
    "            \n",
    "    chain = prompt | model\n",
    "    \n",
    "    print(f\"\\nDisplaying message type order:\")\n",
    "    for message in state[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            print(f\"HumanMessage\")\n",
    "        elif isinstance(message, AIMessage):\n",
    "            print(f\"AIMessage\")\n",
    "    print(f\"\\n\")\n",
    "    \n",
    "    documents = state.get(\"documents\", [])\n",
    "    if documents:\n",
    "        print(f\"Documents found!\")\n",
    "        system_message = f\"Previous conversations that may aid your response:\\n{documents}\"\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]        \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = chain.invoke(\n",
    "        {\"messages\": messages, \"character\": character, \"game\": game, \"world_setting\": world_setting, \"character_bio\": character_bio, \"speaking_style\": speaking_style}\n",
    "    )\n",
    "    \n",
    "    messages_length = len(state[\"messages\"])\n",
    "    print(f\"Messages length: {messages_length}\")\n",
    "    \n",
    "    return {\"messages\": response}\n",
    "\n",
    "def trim_messages(state: State):\n",
    "    global vector_store\n",
    "    \n",
    "    copied_messages = state[\"messages\"][:]\n",
    "    \n",
    "    current_total_tokens = count_tokens(copied_messages)\n",
    "    print(f\"Current token count: {current_total_tokens}\")\n",
    "    \n",
    "    max_tokens = 100\n",
    "    i = 0\n",
    "    delete_messages = []\n",
    "    \n",
    "    while current_total_tokens > max_tokens and i < len(copied_messages) - 1:\n",
    "        if isinstance(copied_messages[i], HumanMessage):\n",
    "            while i < len(copied_messages) - 1 and isinstance(copied_messages[i], HumanMessage):\n",
    "                i += 1\n",
    "        if isinstance(copied_messages[i], AIMessage):\n",
    "            while i < len(copied_messages) - 1 and isinstance(copied_messages[i], AIMessage):\n",
    "                i += 1\n",
    "        \n",
    "        delete_messages = [RemoveMessage(id=m.id) for m in copied_messages[:i]]\n",
    "        current_total_tokens = count_tokens(copied_messages[i:])\n",
    "    \n",
    "    \n",
    "    # Add messages to RAG\n",
    "    character = state[\"character\"]\n",
    "    long_term_memory = \"\"\n",
    "    for m in copied_messages[:i]:\n",
    "        if isinstance(m, HumanMessage):\n",
    "            long_term_memory += \"User: \" + m.content + \"\\n\"\n",
    "        elif isinstance(m, AIMessage):\n",
    "            long_term_memory += f\"{character}: \" + m.content + \"\\n\"\n",
    "        else:\n",
    "            long_term_memory += f\"Unkown: \" + m.content + \"\\n\"\n",
    "    \n",
    "    print(\"Messages that will be deleted and added to long term memory:\")\n",
    "    print(long_term_memory)\n",
    "    vector_store.add_texts([long_term_memory])\n",
    "    \n",
    "    if i != 0:\n",
    "        print(f\"Exceeded max token count, Trimming...\\nNew token count: {current_total_tokens}\")\n",
    "    return {\"messages\": delete_messages}\n",
    "\n",
    "def retrieve(state: State):    \n",
    "    \n",
    "    rag_query = state[\"messages\"][-1].content\n",
    "    print(f\"Rag Query: {rag_query}\")\n",
    "    documents = retriever.invoke(rag_query, k=10)\n",
    "    \n",
    "    for res in documents:\n",
    "        print(f\"{res.page_content}\")\n",
    "    \n",
    "    return {\"documents\": documents}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"retriever\", retrieve)\n",
    "workflow.add_edge(START, \"retriever\")\n",
    "\n",
    "workflow.add_node(\"trimmer\", trim_messages)\n",
    "workflow.add_edge(\"retriever\", \"trimmer\")\n",
    "\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_edge(\"trimmer\", \"model\")\n",
    "\n",
    "workflow.add_edge(\"model\", END)\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tokenizer weights and initialize helper functions\n",
    "###### Note: This may take a little bit of time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere  \n",
    "\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "co = cohere.ClientV2(api_key=api_key)\n",
    "\n",
    "tokenized_output = co.tokenize(text=\"caterpillar\", model=\"command-r-08-2024\")\n",
    "len(tokenized_output.tokens)\n",
    "\n",
    "def count_tokens(messages):\n",
    "    token_sum = 0\n",
    "    for message in messages:\n",
    "        if not isinstance(message, RemoveMessage):\n",
    "            tokenized_output = co.tokenize(text=message.content, model=\"command-r-08-2024\")\n",
    "            token_sum += len(tokenized_output.tokens)\n",
    "    \n",
    "    return token_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk to to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag Query: My name is Bob\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "User: What is my name?\n",
      "Varre: Why, your name is Bob, is it not? I do hope you haven't forgotten it already, my lambkin. It would be a shame to lose such a unique name so early in your journey.\n",
      "\n",
      "User: Are you sure you do not know my name?\n",
      "Varre: Oh, my lambkin, I do apologize if I've given you the wrong impression. Your name, as you've shared with me, is Bob, is it not? I do hope you haven't forgotten it already. Names are precious, and it would be a shame to lose such a unique identifier so early in your journey.\n",
      "\n",
      "Current token count: 111\n",
      "Messages that will be deleted and added to long term memory:\n",
      "User: How are you?\n",
      "Varre: I, my lambkin? Oh, I'm doing splendidly, thank you for asking. I've been busy, you know, tending to my duties as a humble servant of Luminary Mohg, the Lord of Blood. It's a noble calling, and one that I'm honored to fulfill.\n",
      "\n",
      "Exceeded max token count, Trimming...\n",
      "New token count: 46\n",
      "\n",
      "Displaying message type order:\n",
      "HumanMessage\n",
      "AIMessage\n",
      "HumanMessage\n",
      "\n",
      "\n",
      "Documents found!\n",
      "Messages length: 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n"
     ]
    }
   ],
   "source": [
    "query = \"My name is Bob\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag Query: Hello!\n",
      "User: How many times have I said hello?\n",
      "Varre: Oh, my lambkin, you've said it once, and only once. A single utterance of the word \"hello\" is all it takes to capture my attention.\n",
      "User: Hello!\n",
      "Varre: Ah, there it is again! Another \"hello\" from you, my lambkin. I must say, your enthusiasm is infectious. It's a pleasure to have you here in the Lands Between.\n",
      "\n",
      "User: Hello!\n",
      "Varre: Oh, hello there, my lambkin. A Tarnished, I presume? Come to the Lands Between in search of the Elden Ring, no doubt. Well, you've certainly come to the right place, haven't you?\n",
      "User: How many times have I said hello?\n",
      "Varre: Oh, my lambkin, you've said it once, and only once. A single utterance of the word \"hello\" is all it takes to capture my attention.\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "Current token count: 106\n",
      "Messages that will be deleted and added to long term memory:\n",
      "User: How many times have I said hello?\n",
      "Varre: Oh, my lambkin, you've said it once, and only once. A single utterance of the word \"hello\" is all it takes to capture my attention.\n",
      "\n",
      "Exceeded max token count, Trimming...\n",
      "New token count: 64\n",
      "\n",
      "Displaying message type order:\n",
      "HumanMessage\n",
      "AIMessage\n",
      "HumanMessage\n",
      "\n",
      "\n",
      "Documents found!\n",
      "Messages length: 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh, hello there, my lambkin. A Tarnished, I presume? Come to the Lands Between in search of the Elden Ring, no doubt. Well, you've certainly come to the right place, haven't you?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hello!\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag Query: What is my name?\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "User: Hello!\n",
      "Varre: Oh, hello there, my lambkin. A Tarnished, I presume? Come to the Lands Between in search of the Elden Ring, no doubt. Well, you've certainly come to the right place, haven't you?\n",
      "\n",
      "\n",
      "\n",
      "Current token count: 136\n",
      "Messages that will be deleted and added to long term memory:\n",
      "User: What is my name?\n",
      "Varre: Why, your name is Bob, is it not? I do hope you haven't forgotten it already, my lambkin. It would be a shame to lose such a unique name so early in your journey.\n",
      "\n",
      "Exceeded max token count, Trimming...\n",
      "New token count: 89\n",
      "\n",
      "Displaying message type order:\n",
      "HumanMessage\n",
      "AIMessage\n",
      "HumanMessage\n",
      "AIMessage\n",
      "HumanMessage\n",
      "\n",
      "\n",
      "Documents found!\n",
      "Messages length: 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name, my lambkin, is a mystery to me. But fear not, for in these lands, names hold little significance. It is your actions and the path you choose that will define you. So, let us focus on the journey ahead, and may your name be remembered for the deeds you accomplish.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag Query: How many times have I said hello?\n",
      "User: How many times have I said hello?\n",
      "Varre: Oh, my lambkin, you've said it once, and only once. A single utterance of the word \"hello\" is all it takes to capture my attention.\n",
      "\n",
      "User: How many times have I said hello?\n",
      "Varre: Oh, my lambkin, you've said it once, and only once. A single utterance of the word \"hello\" is all it takes to capture my attention.\n",
      "User: Hello!\n",
      "Varre: Ah, there it is again! Another \"hello\" from you, my lambkin. I must say, your enthusiasm is infectious. It's a pleasure to have you here in the Lands Between.\n",
      "\n",
      "User: Hello!\n",
      "Varre: Oh, hello there, my lambkin. A Tarnished, I presume? Come to the Lands Between in search of the Elden Ring, no doubt. Well, you've certainly come to the right place, haven't you?\n",
      "User: How many times have I said hello?\n",
      "Varre: Oh, my lambkin, you've said it once, and only once. A single utterance of the word \"hello\" is all it takes to capture my attention.\n",
      "\n",
      "User: Are you sure you do not know my name?\n",
      "Varre: Oh, my lambkin, I do apologize if I've given you the wrong impression. Your name, as you've shared with me, is Bob, is it not? I do hope you haven't forgotten it already. Names are precious, and it would be a shame to lose such a unique identifier so early in your journey.\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "Current token count: 119\n",
      "Messages that will be deleted and added to long term memory:\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "Exceeded max token count, Trimming...\n",
      "New token count: 57\n",
      "\n",
      "Displaying message type order:\n",
      "HumanMessage\n",
      "AIMessage\n",
      "HumanMessage\n",
      "\n",
      "\n",
      "Documents found!\n",
      "Messages length: 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh, my lambkin, you've said it once, and only once. A single utterance of the word \"hello\" is all it takes to capture my attention.\n"
     ]
    }
   ],
   "source": [
    "query = \"How many times have I said hello?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag Query: How are you?\n",
      "User: How are you?\n",
      "Varre: I, my lambkin? Oh, I'm doing splendidly, thank you for asking. I've been busy, you know, tending to my duties as a humble servant of Luminary Mohg, the Lord of Blood. It's a noble calling, and one that I'm honored to fulfill.\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "\n",
      "\n",
      "Current token count: 95\n",
      "Messages that will be deleted and added to long term memory:\n",
      "\n",
      "\n",
      "Displaying message type order:\n",
      "HumanMessage\n",
      "AIMessage\n",
      "HumanMessage\n",
      "AIMessage\n",
      "HumanMessage\n",
      "\n",
      "\n",
      "Documents found!\n",
      "Messages length: 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I, my lambkin? Oh, I'm doing splendidly, thank you for asking. I've been busy, you know, tending to my duties as a humble servant of Luminary Mohg, the Lord of Blood. It's a noble calling, and one that I'm honored to fulfill.\n"
     ]
    }
   ],
   "source": [
    "query = \"How are you?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag Query: Are you sure you do not know my name?\n",
      "User: What is my name?\n",
      "Varre: Why, your name is Bob, is it not? I do hope you haven't forgotten it already, my lambkin. It would be a shame to lose such a unique name so early in your journey.\n",
      "\n",
      "User: My name is Bob\n",
      "Varre: Bob, is it? Well, Bob, it's a pleasure to make your acquaintance. I am Varre, a humble servant of Luminary Mohg, the Lord of Blood. But enough about me. Tell me, Bob, have you come to these lands seeking guidance and purpose?\n",
      "\n",
      "User: Hello!\n",
      "Varre: Oh, hello there, my lambkin. A Tarnished, I presume? Come to the Lands Between in search of the Elden Ring, no doubt. Well, you've certainly come to the right place, haven't you?\n",
      "\n",
      "\n",
      "Current token count: 162\n",
      "Messages that will be deleted and added to long term memory:\n",
      "User: How many times have I said hello?\n",
      "Varre: Oh, my lambkin, you've said it once, and only once. A single utterance of the word \"hello\" is all it takes to capture my attention.\n",
      "User: Hello!\n",
      "Varre: Ah, there it is again! Another \"hello\" from you, my lambkin. I must say, your enthusiasm is infectious. It's a pleasure to have you here in the Lands Between.\n",
      "\n",
      "Exceeded max token count, Trimming...\n",
      "New token count: 78\n",
      "\n",
      "Displaying message type order:\n",
      "HumanMessage\n",
      "AIMessage\n",
      "HumanMessage\n",
      "\n",
      "\n",
      "Documents found!\n",
      "Messages length: 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh, my lambkin, I do apologize if I've given you the wrong impression. Your name, as you've shared with me, is Bob, is it not? I do hope you haven't forgotten it already. Names are precious, and it would be a shame to lose such a unique identifier so early in your journey.\n"
     ]
    }
   ],
   "source": [
    "query = \"Are you sure you do not know my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_state = app.get_state(config)\n",
    "graph_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
