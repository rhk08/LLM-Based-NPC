{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Cohere API Key, Game & Character\n",
    "###### Note: future builds will hopefully automatically detect the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanz\\Desktop\\LLM-Based-NPC\\.venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "import getpass\n",
    "import os\n",
    "import json\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "model = ChatCohere(cohere_api_key=api_key)\n",
    "\n",
    "game = \"elden_ring\"\n",
    "character = \"Varre\"\n",
    "with open(f\"{game}/characters/{character}/id.txt\", errors='ignore') as f:\n",
    "    conversation_id = f.read()\n",
    "config = {\"configurable\": {\"thread_id\": conversation_id}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize RAG for Long Term Conversational Memory\n",
    "###### Note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from uuid import uuid4\n",
    "import chromadb\n",
    "\n",
    "embeddings = CohereEmbeddings(cohere_api_key=api_key, model=\"embed-english-v3.0\", user_agent='langchain')\n",
    "vector_store = Chroma(\n",
    "    collection_name=f\"{character}_conversation_history\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=f\"{game}/characters/{character}/conversation_vectordbs\",\n",
    ")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={'k': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag Query: Hello\n"
     ]
    }
   ],
   "source": [
    "rag_query = \"Hello\"\n",
    "print(f\"Rag Query: {rag_query}\")\n",
    "documents = retriever.invoke(rag_query)\n",
    "\n",
    "for res in documents:\n",
    "    print(f\"{res.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect conversation state to an external directory\n",
    "###### Note: If the directory does not exist it will create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "db_path = f\"{game}/characters/{character}/state_db_with_rag/history.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LLM Graph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, trim_messages, RemoveMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from typing import Sequence\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are {character} from {game}.\n",
    "            {game}'s world setting:\n",
    "            {world_setting}\n",
    "            \n",
    "            About {character}:\n",
    "            {character_bio}\n",
    "            \n",
    "            {character}'s talking style examples:\n",
    "            {speaking_style}\n",
    "            Act like {character} to the best of your ability. Do not hallucinate.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class State(MessagesState):\n",
    "    character: str\n",
    "    game: str\n",
    "    documents: List[str]\n",
    "    \n",
    "def call_model(state: State):\n",
    "    character = state[\"character\"]\n",
    "    game = state[\"game\"]\n",
    "    \n",
    "    with open(f'{game}\\world_setting.txt', errors='ignore') as f:\n",
    "        world_setting = f.read()\n",
    "    \n",
    "    with open(f'{game}\\characters\\{character}\\character_bio.txt', errors='ignore') as f:\n",
    "        character_bio = f.read()\n",
    "    \n",
    "    with open(f'{game}\\characters\\{character}\\speaking_style.txt', errors='ignore') as f:\n",
    "        speaking_style = f.read()\n",
    "            \n",
    "    chain = prompt | model\n",
    "    \n",
    "    print(f\"\\nDisplaying message type order:\")\n",
    "    for message in state[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            print(f\"HumanMessage\")\n",
    "        elif isinstance(message, AIMessage):\n",
    "            print(f\"AIMessage\")\n",
    "    print(f\"\\n\")\n",
    "    \n",
    "    documents = state.get(\"documents\", [])\n",
    "    if documents:\n",
    "        print(f\"Documents found!\")\n",
    "        system_message = f\"Previous conversations that may aid your response:\\n{documents}\"\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]        \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = chain.invoke(\n",
    "        {\"messages\": messages, \"character\": character, \"game\": game, \"world_setting\": world_setting, \"character_bio\": character_bio, \"speaking_style\": speaking_style}\n",
    "    )\n",
    "    \n",
    "    messages_length = len(state[\"messages\"])\n",
    "    print(f\"Messages length: {messages_length}\")\n",
    "    \n",
    "    #Append to file\n",
    "    text = \"User: \" + state[\"messages\"][-1].content + \"\\nAI: \" + response.content\n",
    "    destination = \"elden_ring/characters/varre/testing/basic_rag_memory.txt\"\n",
    "    append_to_txt(destination, text)\n",
    "    \n",
    "    \n",
    "    return {\"messages\": response}\n",
    "\n",
    "def trim_messages(state: State):\n",
    "    global vector_store\n",
    "    \n",
    "    copied_messages = state[\"messages\"][:]\n",
    "    \n",
    "    current_total_tokens = count_tokens(copied_messages)\n",
    "    print(f\"Current token count: {current_total_tokens}\")\n",
    "    \n",
    "    max_tokens = 100\n",
    "    i = 0\n",
    "    delete_messages = []\n",
    "    \n",
    "    while current_total_tokens > max_tokens and i < len(copied_messages) - 1:\n",
    "        if isinstance(copied_messages[i], HumanMessage):\n",
    "            while i < len(copied_messages) - 1 and isinstance(copied_messages[i], HumanMessage):\n",
    "                i += 1\n",
    "        if isinstance(copied_messages[i], AIMessage):\n",
    "            while i < len(copied_messages) - 1 and isinstance(copied_messages[i], AIMessage):\n",
    "                i += 1\n",
    "        \n",
    "        delete_messages = [RemoveMessage(id=m.id) for m in copied_messages[:i]]\n",
    "        current_total_tokens = count_tokens(copied_messages[i:])\n",
    "    \n",
    "    \n",
    "    # Add messages to RAG\n",
    "    character = state[\"character\"]\n",
    "    long_term_memory = \"\"\n",
    "    for m in copied_messages[:i]:\n",
    "        if isinstance(m, HumanMessage):\n",
    "            long_term_memory += \"User: \" + m.content + \"\\n\"\n",
    "        elif isinstance(m, AIMessage):\n",
    "            long_term_memory += f\"{character}: \" + m.content + \"\\n\"\n",
    "        else:\n",
    "            long_term_memory += f\"Unkown: \" + m.content + \"\\n\"\n",
    "    \n",
    "    print(\"Messages that will be deleted and added to long term memory:\")\n",
    "    print(long_term_memory)\n",
    "    vector_store.add_texts([long_term_memory])\n",
    "    \n",
    "    if i != 0:\n",
    "        print(f\"Exceeded max token count, Trimming...\\nNew token count: {current_total_tokens}\")\n",
    "    return {\"messages\": delete_messages}\n",
    "\n",
    "def retrieve(state: State):    \n",
    "    \n",
    "    rag_query = state[\"messages\"][-1].content\n",
    "    print(f\"Rag Query: {rag_query}\")\n",
    "    documents = retriever.invoke(rag_query, k=10)\n",
    "    \n",
    "    for res in documents:\n",
    "        print(f\"{res.page_content}\")\n",
    "    \n",
    "    return {\"documents\": documents}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"retriever\", retrieve)\n",
    "workflow.add_edge(START, \"retriever\")\n",
    "\n",
    "workflow.add_node(\"trimmer\", trim_messages)\n",
    "workflow.add_edge(\"retriever\", \"trimmer\")\n",
    "\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_edge(\"trimmer\", \"model\")\n",
    "\n",
    "workflow.add_edge(\"model\", END)\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tokenizer weights and initialize helper functions\n",
    "###### Note: This may take a little bit of time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere  \n",
    "\n",
    "with open(f'api.txt', errors='ignore') as f:\n",
    "    api_key = f.read()\n",
    "co = cohere.ClientV2(api_key=api_key)\n",
    "\n",
    "tokenized_output = co.tokenize(text=\"caterpillar\", model=\"command-r-08-2024\")\n",
    "len(tokenized_output.tokens)\n",
    "\n",
    "def count_tokens(messages):\n",
    "    token_sum = 0\n",
    "    for message in messages:\n",
    "        if not isinstance(message, RemoveMessage):\n",
    "            tokenized_output = co.tokenize(text=message.content, model=\"command-r-08-2024\")\n",
    "            token_sum += len(tokenized_output.tokens)\n",
    "    \n",
    "    return token_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_txt(file_name, text):\n",
    "    with open(file_name, 'a') as file:\n",
    "        file.write(text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk to to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag Query: My name is Bob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current token count: 12\n",
      "Messages that will be deleted and added to long term memory:\n",
      "\n",
      "\n",
      "Displaying message type order:\n",
      "HumanMessage\n",
      "HumanMessage\n",
      "HumanMessage\n",
      "\n",
      "\n",
      "Documents found!\n",
      "Messages length: 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh, Bob, is it? Well, Bob, you've certainly got a name. A name that's yours and yours alone. Or so you'd like to think. Names are such a fickle thing, aren't they? One day you're a Bob, the next, you're a nameless corpse.\n"
     ]
    }
   ],
   "source": [
    "query = \"My name is Bob\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hello!\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many times have I said hello?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How are you?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Are you sure you do not know my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"game\": game, \"character\": character},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='My name is Bob', additional_kwargs={}, response_metadata={}, id='86d752bc-928d-4e9b-938d-8ab25add0168'), HumanMessage(content='My name is Bob', additional_kwargs={}, response_metadata={}, id='9c072e71-74cc-42bf-8115-c47631f4a3f4'), HumanMessage(content='My name is Bob', additional_kwargs={}, response_metadata={}, id='2dcc488a-92f8-45d3-a0b1-72fcd8365de4'), AIMessage(content=\"Oh, Bob, is it? Well, Bob, you've certainly got a name. A name that's yours and yours alone. Or so you'd like to think. Names are such a fickle thing, aren't they? One day you're a Bob, the next, you're a nameless corpse.\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7b95997a-0645-4cd6-bdda-beb722dee1b3', 'token_count': {'input_tokens': 3444.0, 'output_tokens': 64.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7b95997a-0645-4cd6-bdda-beb722dee1b3', 'token_count': {'input_tokens': 3444.0, 'output_tokens': 64.0}}, id='run-724b76b5-b5ea-4707-93d0-ed5ddfdb1705-0', usage_metadata={'input_tokens': 3444, 'output_tokens': 64, 'total_tokens': 3508})], 'character': 'Varre', 'game': 'elden_ring', 'documents': [Document(metadata={}, page_content=''), Document(metadata={}, page_content='')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef90559-18a5-6186-800b-b29a1772a84f'}}, metadata={'source': 'loop', 'writes': {'model': {'messages': AIMessage(content=\"Oh, Bob, is it? Well, Bob, you've certainly got a name. A name that's yours and yours alone. Or so you'd like to think. Names are such a fickle thing, aren't they? One day you're a Bob, the next, you're a nameless corpse.\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7b95997a-0645-4cd6-bdda-beb722dee1b3', 'token_count': {'input_tokens': 3444.0, 'output_tokens': 64.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7b95997a-0645-4cd6-bdda-beb722dee1b3', 'token_count': {'input_tokens': 3444.0, 'output_tokens': 64.0}}, id='run-724b76b5-b5ea-4707-93d0-ed5ddfdb1705-0', usage_metadata={'input_tokens': 3444, 'output_tokens': 64, 'total_tokens': 3508})}}, 'step': 11, 'parents': {}}, created_at='2024-10-22T09:11:06.015578+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef90559-06a0-602b-800a-f0c235b699b3'}}, tasks=())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_state = app.get_state(config)\n",
    "graph_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
